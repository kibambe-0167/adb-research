{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load numpy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 32, 32, 3), (19999,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load first datasets\n",
    "cifer10 = np.load(\"./loaded_data/cifer10_x_train.npy\")\n",
    "# create labels\n",
    "cifer10_labels = np.zeros(cifer10.shape[0]-1, dtype=int )\n",
    "cifer10.shape, cifer10_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load first faces datasets\n",
    "faces1 = np.load(\"./loaded_data/first_10K.npy\")\n",
    "faces1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load second faces datasets\n",
    "faces2 = np.load(\"./loaded_data/second_10K.npy\")\n",
    "faces2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 32, 32, 3) (19999,)\n"
     ]
    }
   ],
   "source": [
    "# concatenate arrays, and create calss labels.\n",
    "faces = np.concatenate((faces1, faces2), axis=0)\n",
    "faces_label = np.ones(faces.shape[0], dtype=int)\n",
    "print(faces.shape, faces_label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make train and evaluate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "(15000, 32, 32, 3),\n",
      "(2500, 32, 32, 3),\n",
      "(2499, 32, 32, 3)\n",
      "\n",
      "Labels:\n",
      "(15000,),\n",
      "(2500,),\n",
      "(2499,)\n"
     ]
    }
   ],
   "source": [
    "# faces\n",
    "faces_train_data = faces[: 15000]; faces_label_train = faces_label[:15000]\n",
    "faces_test_data = faces[15000: 17500] ; faces_label_test = faces_label[15000: 17500]\n",
    "faces_eval_data = faces[17500: ] ; faces_label_eval = faces_label[17500: ]\n",
    "print( f\"Data:\\n{faces_train_data.shape},\\n{faces_test_data.shape},\\n{faces_eval_data.shape}\" )\n",
    "print( f\"\\nLabels:\\n{faces_label_train.shape},\\n{faces_label_test.shape},\\n{faces_label_eval.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "(15000, 32, 32, 3),\n",
      "(2500, 32, 32, 3),\n",
      "(2499, 32, 32, 3)\n",
      "\n",
      "Labels:\n",
      "(15000,),\n",
      "(2500,),\n",
      "(2499,)\n"
     ]
    }
   ],
   "source": [
    "# random images\n",
    "cifer10_train_data = cifer10[: 15000]; cifer10_label_train = cifer10_labels[:15000]\n",
    "cifer10_test_data = cifer10[15000: 17500] ; cifer10_label_test = cifer10_labels[15000: 17500]\n",
    "cifer10_eval_data = cifer10[17500: -1] ; cifer10_label_eval = cifer10_labels[17500: ]\n",
    "print( f\"Data:\\n{cifer10_train_data.shape},\\n{cifer10_test_data.shape},\\n{cifer10_eval_data.shape}\" )\n",
    "print( f\"\\nLabels:\\n{cifer10_label_train.shape},\\n{cifer10_label_test.shape},\\n{cifer10_label_eval.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise data\n",
    "cifer_td = cifer10_train_data / 255.0\n",
    "cifer_ed = cifer10_eval_data / 255.0\n",
    "cifer_tsd = cifer10_test_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 32, 32, 3), (30000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate train data\n",
    "x_train = np.concatenate((faces_train_data, cifer_td), axis=0)\n",
    "y_train = np.concatenate((faces_label_train, cifer10_label_train ), axis=0)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 32, 32, 3), (5000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate test data\n",
    "x_test = np.concatenate(( faces_test_data, cifer_tsd ), axis=0)\n",
    "y_test = np.concatenate(( faces_label_test, cifer10_label_test ), axis=0 )\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4998, 32, 32, 3), (4998,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate test data\n",
    "x_eval = np.concatenate((faces_eval_data, cifer10_eval_data ), axis=0)\n",
    "y_eval = np.concatenate((faces_label_eval, cifer10_label_eval ), axis=0)\n",
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalise datasets and reshape datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (30000, 3072) \n",
      "x_test: (5000, 3072) \n",
      "x_eval: (4998, 3072)\n"
     ]
    }
   ],
   "source": [
    "# reshape datasets\n",
    "x_train_data = x_train.reshape((x_train.shape[0], -1 ))\n",
    "# \n",
    "x_test_data = x_test.reshape((x_test.shape[0], -1))\n",
    "# \n",
    "x_eval_data = x_eval.reshape(x_eval.shape[0], -1)\n",
    "# \n",
    "print(f\"x_train: {x_train_data.shape} \\nx_test: {x_test_data.shape} \\nx_eval: {x_eval_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09411765, 0.09803922, 0.11372549],\n",
       "       [0.08627451, 0.09019608, 0.10588235],\n",
       "       [0.0745098 , 0.07843137, 0.09411765],\n",
       "       [0.06666667, 0.07058824, 0.08627451],\n",
       "       [0.06666667, 0.07058824, 0.08627451],\n",
       "       [0.05098039, 0.05490196, 0.07058824],\n",
       "       [0.03921569, 0.04313725, 0.05098039],\n",
       "       [0.03921569, 0.04313725, 0.05098039],\n",
       "       [0.02745098, 0.03137255, 0.03921569],\n",
       "       [0.02745098, 0.03137255, 0.03921569],\n",
       "       [0.02745098, 0.03137255, 0.03921569],\n",
       "       [0.03137255, 0.03529412, 0.04313725],\n",
       "       [0.02352941, 0.02352941, 0.03137255],\n",
       "       [0.01568627, 0.01568627, 0.02352941],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01176471],\n",
       "       [0.01568627, 0.01568627, 0.01176471],\n",
       "       [0.01568627, 0.01176471, 0.01176471],\n",
       "       [0.01568627, 0.01568627, 0.01176471],\n",
       "       [0.01568627, 0.01176471, 0.01176471],\n",
       "       [0.01176471, 0.01176471, 0.01568627],\n",
       "       [0.01176471, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01176471],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01568627, 0.01568627, 0.01568627],\n",
       "       [0.01960784, 0.01960784, 0.01960784],\n",
       "       [0.01960784, 0.01960784, 0.01960784]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_data.shape)\n",
    "x_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "# Assuming your reshaped data has shape (30000, 32, 32, 3)\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Define the input layer\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# Convert the 3D input to a sequence of 1D vectors\n",
    "x = layers.Reshape((32*32, 3))(inputs)\n",
    "# Bidirectional LSTM layer\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Dropout layer\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Output layer for binary classification\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "# Create the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 168s 178ms/step - loss: 0.6402 - accuracy: 0.6397 - val_loss: 0.6030 - val_accuracy: 0.7255\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 172s 183ms/step - loss: 0.6818 - accuracy: 0.5753 - val_loss: 0.6151 - val_accuracy: 0.7343\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 182s 194ms/step - loss: 0.6742 - accuracy: 0.5686 - val_loss: 0.6186 - val_accuracy: 0.7369\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 190s 202ms/step - loss: 0.6869 - accuracy: 0.5478 - val_loss: 0.5681 - val_accuracy: 0.6803\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 184s 196ms/step - loss: 0.6792 - accuracy: 0.5691 - val_loss: 0.4880 - val_accuracy: 0.7905\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 186s 198ms/step - loss: 0.6628 - accuracy: 0.5964 - val_loss: 0.4343 - val_accuracy: 0.8631\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 179s 191ms/step - loss: 0.6335 - accuracy: 0.6381 - val_loss: 0.6609 - val_accuracy: 0.5990\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 186s 198ms/step - loss: 0.6478 - accuracy: 0.6452 - val_loss: 0.7094 - val_accuracy: 0.4712\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 200s 214ms/step - loss: 0.7101 - accuracy: 0.5240 - val_loss: 0.6263 - val_accuracy: 0.6497\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 205s 218ms/step - loss: 0.6920 - accuracy: 0.5371 - val_loss: 0.5557 - val_accuracy: 0.7725\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.5557 - accuracy: 0.7725\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 205s 218ms/step - loss: 0.6873 - accuracy: 0.5449 - val_loss: 0.6507 - val_accuracy: 0.7281\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 203s 217ms/step - loss: 0.6892 - accuracy: 0.5403 - val_loss: 0.6360 - val_accuracy: 0.7439\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 202s 215ms/step - loss: 0.6499 - accuracy: 0.6168 - val_loss: 0.7221 - val_accuracy: 0.7057\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 204s 217ms/step - loss: 0.6792 - accuracy: 0.5663 - val_loss: 0.6950 - val_accuracy: 0.3231\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 203s 216ms/step - loss: 0.6563 - accuracy: 0.6120 - val_loss: 0.6297 - val_accuracy: 0.5594\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 201s 214ms/step - loss: 0.6136 - accuracy: 0.6675 - val_loss: 0.8057 - val_accuracy: 0.3133\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 194s 207ms/step - loss: 0.6074 - accuracy: 0.6772 - val_loss: 0.5028 - val_accuracy: 0.8179\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.6557 - accuracy: 0.6237 - val_loss: 0.5729 - val_accuracy: 0.6425\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.6702 - accuracy: 0.5818 - val_loss: 0.6329 - val_accuracy: 0.6919\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 200s 213ms/step - loss: 0.6560 - accuracy: 0.6121 - val_loss: 0.6891 - val_accuracy: 0.4150\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.6891 - accuracy: 0.4150\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 205s 218ms/step - loss: 0.6724 - accuracy: 0.5884 - val_loss: 0.7758 - val_accuracy: 0.3471\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 201s 214ms/step - loss: 0.6879 - accuracy: 0.5466 - val_loss: 0.6523 - val_accuracy: 0.7159\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 193s 205ms/step - loss: 0.6641 - accuracy: 0.5986 - val_loss: 0.7344 - val_accuracy: 0.4480\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1549s 2s/step - loss: 0.6484 - accuracy: 0.6170 - val_loss: 0.6850 - val_accuracy: 0.6385\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 505s 539ms/step - loss: 0.6101 - accuracy: 0.6653 - val_loss: 0.8763 - val_accuracy: 0.3906\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 163s 174ms/step - loss: 0.6113 - accuracy: 0.6653 - val_loss: 0.9429 - val_accuracy: 0.1767\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 169s 180ms/step - loss: 0.6603 - accuracy: 0.6071 - val_loss: 0.9257 - val_accuracy: 0.3171\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 172s 184ms/step - loss: 0.6582 - accuracy: 0.6048 - val_loss: 0.9152 - val_accuracy: 0.3259\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 170s 181ms/step - loss: 0.6029 - accuracy: 0.6768 - val_loss: 0.9730 - val_accuracy: 0.3830\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 179s 191ms/step - loss: 0.5705 - accuracy: 0.6997 - val_loss: 1.1887 - val_accuracy: 0.3291\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 1.1887 - accuracy: 0.3291\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 178s 190ms/step - loss: 0.4682 - accuracy: 0.7979 - val_loss: 1.5215 - val_accuracy: 0.3892\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.5591 - accuracy: 0.7110 - val_loss: 0.7504 - val_accuracy: 0.3049\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 186s 199ms/step - loss: 0.5438 - accuracy: 0.7300 - val_loss: 0.7069 - val_accuracy: 0.4528\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 179s 191ms/step - loss: 0.4813 - accuracy: 0.7803 - val_loss: 0.8636 - val_accuracy: 0.4340\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 181s 193ms/step - loss: 0.4408 - accuracy: 0.8091 - val_loss: 0.5261 - val_accuracy: 0.5060\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 186s 199ms/step - loss: 0.6448 - accuracy: 0.6365 - val_loss: 0.8280 - val_accuracy: 0.3021\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 180s 192ms/step - loss: 0.4669 - accuracy: 0.7872 - val_loss: 1.0129 - val_accuracy: 0.4214\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.4993 - accuracy: 0.7458 - val_loss: 0.9864 - val_accuracy: 0.3880\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 181s 193ms/step - loss: 0.5563 - accuracy: 0.7323 - val_loss: 0.5617 - val_accuracy: 0.6471\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 189s 201ms/step - loss: 0.4945 - accuracy: 0.7866 - val_loss: 0.6286 - val_accuracy: 0.4910\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.6286 - accuracy: 0.4910\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 193s 205ms/step - loss: 0.4476 - accuracy: 0.8165 - val_loss: 0.7337 - val_accuracy: 0.4522\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 186s 198ms/step - loss: 0.4195 - accuracy: 0.8292 - val_loss: 0.5768 - val_accuracy: 0.5168\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.6164 - accuracy: 0.6577 - val_loss: 0.6315 - val_accuracy: 0.6146\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 185s 197ms/step - loss: 0.5271 - accuracy: 0.7421 - val_loss: 0.7596 - val_accuracy: 0.4398\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 186s 198ms/step - loss: 0.4347 - accuracy: 0.8114 - val_loss: 0.7889 - val_accuracy: 0.4480\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 187s 199ms/step - loss: 0.4130 - accuracy: 0.8242 - val_loss: 0.8931 - val_accuracy: 0.4528\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 183s 195ms/step - loss: 0.3616 - accuracy: 0.8492 - val_loss: 0.9287 - val_accuracy: 0.4786\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 186s 199ms/step - loss: 0.3588 - accuracy: 0.8495 - val_loss: 1.0526 - val_accuracy: 0.4238\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 182s 194ms/step - loss: 0.2977 - accuracy: 0.8807 - val_loss: 0.8902 - val_accuracy: 0.4676\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 183s 195ms/step - loss: 0.2707 - accuracy: 0.8942 - val_loss: 0.8188 - val_accuracy: 0.4904\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.8188 - accuracy: 0.4904\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32\n",
    "epoch = 10\n",
    "validation_accuracies = []\n",
    "\n",
    "for _ in range(5):\n",
    "    # Train and evaluate the model on the validation set\n",
    "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=True, validation_data=(x_eval, y_eval) )\n",
    "    _, accuracy = model.evaluate(x_eval, y_eval)\n",
    "    validation_accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959689241794617\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "mean_accuracy = np.mean(validation_accuracies)\n",
    "std_accuracy = np.std(validation_accuracies)\n",
    "\n",
    "# Perform one-sample t-test\n",
    "null_hypothesis = 0.5  # Null hypothesis assumes random chance performance\n",
    "t_statistic, p_value = ttest_1samp(validation_accuracies, null_hypothesis)\n",
    "\n",
    "# Compare the obtained p-value with the significance level\n",
    "alpha = 0.05\n",
    "print( p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if p_value < alpha:\n",
    "#     print(\"The model's performance is statistically significant.\")\n",
    "# else:\n",
    "#     print(\"The model's performance is not statistically significant.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using sequential api from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming your input shape is (32, 32, 3)\n",
    "input_shape = (32, 32, 3)\n",
    "dropout_rate = 0.25\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "# Add a Bidirectional layer\n",
    "model.add(Bidirectional(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape)))\n",
    "# Add MaxPooling2D, Flatten, and Dense layers\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# Add Dropout layer\n",
    "model.add(Dropout(dropout_rate))\n",
    "# Add the final Dense layer with sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# second model training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_eval, y_eval), epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, callbacks\u001b[39m=\u001b[39m[early_stopping])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "# second model training\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_eval, y_eval), epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-adb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
